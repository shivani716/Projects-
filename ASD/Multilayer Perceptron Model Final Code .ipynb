{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fef68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\Thesis_TF\\tfvenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1721\n",
      "           1       0.93      0.94      0.94       586\n",
      "\n",
      "    accuracy                           0.97      2307\n",
      "   macro avg       0.96      0.96      0.96      2307\n",
      "weighted avg       0.97      0.97      0.97      2307\n",
      "\n",
      "\n",
      "Accuracy Score of the MLP model:\n",
      "Accuracy: 96.71%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['thesis_db']  # Replace with your database name\n",
    "collection = db['research_data']  # Replace with your collection name\n",
    "\n",
    "# Retrieve data from MongoDB\n",
    "data = list(collection.find())\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop the MongoDB '_id' field if it exists\n",
    "if '_id' in df.columns:\n",
    "    df = df.drop('_id', axis=1)\n",
    "\n",
    "# Data Cleaning and Preprocessing\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "label_encoder = LabelEncoder()\n",
    "df['Class/ASD'] = label_encoder.fit_transform(df['Class/ASD'])\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "df_selected = df_encoded.select_dtypes(include=[np.number])\n",
    " \n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(df_selected)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "pca_df.to_csv('pca_transformed_data.csv', index=False)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_encoded.drop(columns=['Class/ASD'])\n",
    "y = df['Class/ASD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV with fewer iterations and simpler search space\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(50,), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'learning_rate': ['constant'],\n",
    "    'alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    MLPClassifier(solver='adam', max_iter=200, random_state=42, early_stopping=True),\n",
    "    param_distributions,\n",
    "    n_iter=10,  # Reduce n_iter for quicker results\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train the MLP model with the best parameters\n",
    "mlp_best = MLPClassifier(**best_params, solver='adam', max_iter=200, random_state=42, early_stopping=True)\n",
    "mlp_best.fit(X_train, y_train)\n",
    "\n",
    "# Save accuracy and loss history\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': np.arange(len(mlp_best.loss_curve_)),\n",
    "    'loss': mlp_best.loss_curve_,\n",
    "    'accuracy': mlp_best.score(X_train, y_train)\n",
    "})\n",
    "history_df.to_csv('mlp_training_history.csv', index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = mlp_best.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score of the MLP model:\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "df_selected['Predicted'] = mlp_best.predict(X)\n",
    "df_selected['Actual'] = df['Class/ASD']\n",
    "df_selected.to_csv('MLP_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0873208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
